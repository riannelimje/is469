{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4044caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install accelerate datasets transformers evaluate\n",
    "import torch, transformers, datasets, accelerate, evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate.utils.memory import clear_device_cache\n",
    "from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_split_names(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].features # features of the 'train' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aecb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][17] #random example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48202289",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a685d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = small_train_dataset.map(tokenize_function, batched=True)\n",
    "small_eval_dataset = small_eval_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e595b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  logits, labels = eval_pred\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fe7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16, # we want to train this and don't touch eval\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01, # regularisor - reduce overfitting (same idea as dropout but mechanism diff)\n",
    "    warmup_ratio=0.1,\n",
    "    gradient_accumulation_steps=2, # similar to batch size \n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.999,\n",
    "    adam_epsilon=1e-08,\n",
    "    logging_dir='.logs',\n",
    "    logging_steps=10,\n",
    "    output_dir=\"test_trainer\",\n",
    "    eval_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa205fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
